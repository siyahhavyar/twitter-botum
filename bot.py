import os
import requests
import time
import random
import google.generativeai as genai
import tweepy

# --- ÅÄ°FRELER ---
GEMINI_API_KEY = os.environ.get("GEMINI_KEY")
CONSUMER_KEY = os.environ.get("API_KEY")
CONSUMER_SECRET = os.environ.get("API_SECRET")
ACCESS_TOKEN = os.environ.get("ACCESS_TOKEN")
ACCESS_SECRET = os.environ.get("ACCESS_SECRET")

# --- HUGGING FACE TOKEN LÄ°STESÄ° (Yedekli Sistem) ---
hf_tokens = [
    os.environ.get("HF_TOKEN_1"),
    os.environ.get("HF_TOKEN_2"),
    os.environ.get("HF_TOKEN_3"),
    os.environ.get("HF_TOKEN_4"),
    os.environ.get("HF_TOKEN_5"),
    os.environ.get("HF_TOKEN_6")
]
valid_tokens = [t for t in hf_tokens if t]

# --- YENÄ° MODEL LÄ°STESÄ° (Ã‡alÄ±ÅŸanlar) ---
# Playground kapandÄ±ÄŸÄ± iÃ§in FLUX ve SD 3.5'e geÃ§tik.
MODELS_TO_TRY = [
    "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-dev",
    "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-3.5-large",
    "https://api-inference.huggingface.co/models/ByteDance/SDXL-Lightning"
]

def get_image_prompt():
    print("Gemini 1.5: Konu dÃ¼ÅŸÃ¼nÃ¼lÃ¼yor...")
    try:
        # Python sÃ¼rÃ¼mÃ¼nÃ¼ yÃ¼kselttiÄŸimiz iÃ§in artÄ±k 1.5 Flash Ã§alÄ±ÅŸacak
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        instruction = """
        You are an AI Wallpaper Art Director.
        Goal: Create a prompt for FLUX.1 AI.
        Style: "Vector Art", "Anime Background", "Digital Illustration".
        Rules: NO "Realistic", NO "3D Render" (To avoid blur).
        Subject: Cyberpunk city, Japanese Aesthetic, Space, Minimalist Nature.
        Output: ONLY the prompt text.
        """
        
        response = model.generate_content(instruction)
        prompt = response.text.strip()
        final_prompt = prompt + ", vector art, sharp lines, flat color, cel shaded, 8k resolution, high contrast, masterpiece"
        print(f"Fikir: {prompt}")
        return final_prompt
    except Exception as e:
        print(f"âš ï¸ Gemini HatasÄ±: {e}")
        return "cyberpunk city street with neon lights, vector art, sharp lines, flat colors, 8k resolution"

def query_huggingface_smart(payload):
    # DÄ±ÅŸ DÃ¶ngÃ¼: TOKENLER
    for t_index, token in enumerate(valid_tokens):
        headers = {"Authorization": f"Bearer {token}"}
        
        # Ä°Ã§ DÃ¶ngÃ¼: MODELLER
        for m_index, model_url in enumerate(MODELS_TO_TRY):
            print(f"â¡ï¸ Deneme: Token {t_index+1} -> Model: {model_url.split('/')[-1]}")
            
            for attempt in range(3): # 3 kere dene
                try:
                    response = requests.post(model_url, headers=headers, json=payload)
                    
                    # BAÅARILI
                    if response.status_code == 200:
                        print(f"âœ… BAÅARILI! Resim Ã§izildi.")
                        return response.content
                    
                    # ISINIYOR (Wait)
                    elif "error" in response.json() and "loading" in response.json()["error"]:
                        wait_time = response.json()["estimated_time"]
                        print(f"â³ Model Ä±sÄ±nÄ±yor... {wait_time:.1f}sn bekle.")
                        time.sleep(wait_time + 2)
                        continue
                    
                    # KAPALI MODEL (410) veya BULUNAMADI (404)
                    elif response.status_code in [404, 410]:
                        print(f"âŒ Bu model artÄ±k Ã§alÄ±ÅŸmÄ±yor. Sonrakine geÃ§iliyor.")
                        break # Bu model dÃ¶ngÃ¼sÃ¼nÃ¼ kÄ±r, diÄŸer modele geÃ§
                    
                    # YETKÄ° YOK (403) - Token hatasÄ± olabilir
                    elif response.status_code == 403:
                        print(f"âŒ Bu Token iÃ§in yetki yok. DiÄŸer Tokene geÃ§iliyor.")
                        break # DiÄŸer tokene geÃ§mek iÃ§in
                        
                    else:
                        print(f"âš ï¸ Hata kodu: {response.status_code}. Tekrar deneniyor...")
                        time.sleep(2)
                        
                except Exception as e:
                    print(f"BaÄŸlantÄ± hatasÄ±: {e}")
                    time.sleep(2)
            
            # EÄŸer resim geldiyse fonksiyondan Ã§Ä±k
            # Gelmediyse sonraki modele geÃ§ecek
            
    print("ğŸš¨ HATA: TÃ¼m Tokenler ve Modeller denendi, sonuÃ§ alÄ±namadÄ±.")
    return None

def download_image(prompt):
    print("Hugging Face: Resim Ã§izimi baÅŸlatÄ±lÄ±yor...")
    
    # 1024x1024 Kare (En net sonuÃ§ iÃ§in)
    payload = {
        "inputs": prompt,
        "parameters": {
            "width": 1024,
            "height": 1024,
            "guidance_scale": 7.0,
            "num_inference_steps": 25 # FLUX iÃ§in 25 yeterli
        }
    }
    
    image_bytes = query_huggingface_smart(payload)
    
    if image_bytes:
        filename = "wallpaper_hq.jpg"
        with open(filename, "wb") as f:
            f.write(image_bytes)
        
        if os.path.getsize(filename) < 1000:
            print("âŒ Hata: Ä°nen dosya bozuk.")
            return None
            
        print("ğŸ’¾ Resim baÅŸarÄ±yla kaydedildi.")
        return filename
    else:
        return None

def post_to_twitter(filename, prompt):
    print("Twitter'a yÃ¼kleniyor...")
    try:
        auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
        auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)
        api = tweepy.API(auth)
        
        media = api.media_upload(filename)
        
        client = tweepy.Client(
            consumer_key=CONSUMER_KEY,
            consumer_secret=CONSUMER_SECRET,
            access_token=ACCESS_TOKEN,
            access_token_secret=ACCESS_SECRET
        )
        
        text = "Daily Wallpaper ğŸ¨âœ¨\n#wallpaper #art #ai #4k"
        client.create_tweet(text=text, media_ids=[media.media_id])
        print("âœ… TWEET ATILDI!")
        
    except Exception as e:
        print(f"Twitter HatasÄ±: {e}")

if __name__ == "__main__":
    prompt_text = get_image_prompt()
    image_file = download_image(prompt_text)
    
    if image_file:
        post_to_twitter(image_file, prompt_text)

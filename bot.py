import tweepy
import os
import time
import json
import random
import requests
import google.generativeai as genai

# --- ÅÄ°FRELER ---
api_key = os.environ['API_KEY']
api_secret = os.environ['API_SECRET']
access_token = os.environ['ACCESS_TOKEN']
access_secret = os.environ['ACCESS_SECRET']
GEMINI_KEY = os.environ['GEMINI_KEY']

# --- HF TOKEN LÄ°STESÄ° (AyrÄ± Hesaplar Varsa SÃ¼per!) ---
TOKEN_LISTESI = [
    os.environ.get('HF_TOKEN'), os.environ.get('HF_TOKEN_1'), os.environ.get('HF_TOKEN_2'),
    os.environ.get('HF_TOKEN_3'), os.environ.get('HF_TOKEN_4'), os.environ.get('HF_TOKEN_5'),
    os.environ.get('HF_TOKEN_6'), os.environ.get('HF_TOKEN_7'), os.environ.get('HF_TOKEN_8'),
    os.environ.get('HF_TOKEN_9')
]
TOKEN_LISTESI = [t for t in TOKEN_LISTESI if t]

# --- REPLICATE FALLBACK (Yeni Token Ekle!) ---
REPLICATE_TOKEN = os.environ.get('REPLICATE_TOKEN')  # replicate.com'dan al, free kredi var
REPLICATE_URL = "https://api.replicate.com/v1/predictions"
REPLICATE_MODEL = "black-forest-labs/flux-schnell"  # HÄ±zlÄ± ve Ã¼cretsiz dostu

# --- GEMINI AYARLARI ---
genai.configure(api_key=GEMINI_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

# --- HF API (FLUX) ---
HF_API_URL = "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell"

def get_autonomous_idea():
    print("ğŸ§  Gemini sanat yÃ¶netmeni modunda...")
    
    prompt_emir = """
    Sen benim kiÅŸisel dijital sanat asistanÄ±msÄ±n. Twitter hesabÄ±m iÃ§in 'GÃ¼nÃ¼n Duvar KaÄŸÄ±dÄ±'nÄ± tasarlÄ±yorsun.
    
    GÃ¶revin:
    1. Minimalist DoÄŸa, Cyberpunk, Uzay, SÃ¼rrealizm veya Estetik Geometri konularÄ±ndan birini seÃ§.
    2. Benzersiz, Ã§ok havalÄ± ve 8K kalitesinde duracak bir sahne kurgula.
    
    Bana SADECE ÅŸu JSON formatÄ±nda cevap ver:
    {
      "caption": "Twitter iÃ§in Ä°ngilizce, kÄ±sa, havalÄ±, emojili bir aÃ§Ä±klama. Hashtagler ekle (#Minimalist #Wallpaper #Art #4K #Aesthetic).",
      "image_prompt": "Resmi Ã§izecek yapay zeka iÃ§in Ä°NGÄ°LÄ°ZCE prompt. ÅunlarÄ± MUTLAKA ekle: 'minimalist, clean lines, vertical wallpaper, highly detailed, 8k resolution, masterpiece, cinematic lighting, sharp focus, beautiful composition --no text, no watermark'."
    }
    """
    
    try:
        response = model.generate_content(prompt_emir)
        text = response.text.strip().replace("```json", "").replace("```", "")
        data = json.loads(text)
        print(f"âœ… Fikir Bulundu: {data['caption'][:50]}...")
        return data
    except Exception as e:
        print(f"âš ï¸ Gemini HatasÄ± ({e}), yedek konu kullanÄ±lÄ±yor.")
        return {
            "caption": "Endless horizon at sunset ğŸŒ… Minimalist vibes\n\n#Wallpaper #Minimalist #Art #Aesthetic",
            "image_prompt": "minimalist endless ocean sunset, single boat silhouette, warm colors, vertical wallpaper, 8k, masterpiece, cinematic lighting --no text"
        }

def query_huggingface(payload, token):
    headers = {"Authorization": f"Bearer {token}"}
    response = requests.post(HF_API_URL, headers=headers, json=payload, timeout=180)
    return response

def generate_with_replicate(prompt):
    if not REPLICATE_TOKEN:
        print("âŒ Replicate token yok! replicate.com'dan al.")
        return False
    
    print("ğŸ”„ HF baÅŸarÄ±sÄ±z, Replicate'e geÃ§iliyor...")
    headers = {
        "Authorization": f"Token {REPLICATE_TOKEN}",
        "Content-Type": "application/json"
    }
    data = {
        "version": "1f208f8c8705b9c1389a20dae6d317b9873dacfb9f8236a24d1e57c68e2d1b9e",  # Flux Schnell versiyonu
        "input": {
            "prompt": prompt + ", vertical wallpaper, 8k, detailed",
            "aspect_ratio": "9:16",  # Dikey iÃ§in
            "output_format": "jpg",
            "num_outputs": 1,
            "num_inference_steps": 4
        }
    }
    
    try:
        response = requests.post(REPLICATE_URL, headers=headers, json=data)
        if response.status_code == 201:
            pred_id = response.json()['id']
            # Poll for result
            while True:
                poll = requests.get(f"{REPLICATE_URL}/{pred_id}", headers=headers)
                if poll.status_code == 200 and poll.json().get('status') == 'succeeded':
                    img_url = poll.json()['output'][0]
                    img_data = requests.get(img_url).content
                    with open("tweet_image.jpg", "wb") as f:
                        f.write(img_data)
                    print("âœ… Replicate ile RESÄ°M Ã‡Ä°ZÄ°LDÄ°!")
                    return True
                elif poll.json().get('status') == 'failed':
                    print(f"âŒ Replicate hatasÄ±: {poll.json()}")
                    return False
                time.sleep(5)
        else:
            print(f"âŒ Replicate hata: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Replicate baÄŸlantÄ± hatasÄ±: {e}")
        return False

def generate_image_raw(prompt):
    if not TOKEN_LISTESI:
        print("âŒ HF token yok, direkt Replicate dene.")
        return generate_with_replicate(prompt)
    
    random.shuffle(TOKEN_LISTESI)
    
    for i, token in enumerate(TOKEN_LISTESI):
        print(f"ğŸ”„ {i+1}/{len(TOKEN_LISTESI)} HF token deneniyor...")
        
        payload = {
            "inputs": prompt + ", vertical phone wallpaper, ultra detailed, high quality",
            "parameters": {
                "negative_prompt": "text, watermark, blurry, low quality, deformed",
                "width": 512,
                "height": 768,
                "num_inference_steps": 4,
                "guidance_scale": 3.5
            }
        }
        
        for attempt in range(3):
            try:
                response = query_huggingface(payload, token)
                
                if response.status_code == 503:
                    wait = response.json().get("estimated_time", 30)
                    print(f"ğŸ’¤ HF busy... {wait + 20} sn bekle (Deneme {attempt+1}/3)")
                    time.sleep(wait + 20)
                    continue
                
                if response.status_code == 200:
                    with open("tweet_image.jpg", "wb") as f:
                        f.write(response.content)
                    print(f"âœ… HF ile RESÄ°M Ã‡Ä°ZÄ°LDÄ°! ({i+1}. token)")
                    return True
                
                elif response.status_code in [402, 429] or 'quota' in response.text.lower() or 'exceeded' in response.text.lower() or 'rate' in response.text.lower():
                    print(f"ğŸš« HF quota/rate limit ({response.status_code})! Bu tokenÄ± skip, Replicate'e geÃ§iliyor...")
                    return generate_with_replicate(prompt)  # Direkt Replicate'e atla
                
                else:
                    print(f"âŒ HF Hata {response.status_code}: {response.text[:100]}")
                    time.sleep(10)
                    
            except Exception as e:
                print(f"âŒ HF BaÄŸlantÄ± hatasÄ±: {e}")
                time.sleep(10)
        
        print(f"â­ï¸ {i+1}. HF token skip edildi.")
    
    print("ğŸš¨ HF TÃœMÃœ BAÅARISIZ! Replicate fallback deneniyor...")
    return generate_with_replicate(prompt)

def post_tweet():
    idea = get_autonomous_idea()
    
    if generate_image_raw(idea['image_prompt']):
        print("ğŸ¦ Twitter'a yÃ¼kleniyor...")
        try:
            auth = tweepy.OAuth1UserHandler(api_key, api_secret, access_token, access_secret)
            api = tweepy.API(auth)
            client = tweepy.Client(
                consumer_key=api_key, consumer_secret=api_secret,
                access_token=access_token, access_token_secret=access_secret
            )

            media = api.media_upload("tweet_image.jpg")
            client.create_tweet(text=idea['caption'], media_ids=[media.media_id])
            print("âœ… TWEET BAÅARIYLA ATILDI! ğŸ‰")
            
        except Exception as e:
            print(f"âŒ Twitter hatasÄ±: {e}")
    else:
        print("âŒ Resim Ã§izilemedi. HF quota/IP sorunu â€“ Replicate token ekle veya Pro al. YarÄ±n (1 AralÄ±k) resetlenir!")

if __name__ == "__main__":
    post_tweet()